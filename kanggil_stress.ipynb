{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import monai\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Image input 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input(iterator, batch_size):\n",
    "    for data in iterator:\n",
    "        input = data['img']\n",
    "        label = data['label']\n",
    "        \n",
    "        plt.imshow(torchvision.utils.make_grid(input, normalize=True).permute(1,2,0))\n",
    "        print(''.join(f'{label[i]} 'for i in range(batch_size)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook():\n",
    "    def __init__(self, module, backward = False):\n",
    "        if backward == False:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.features = output\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representations(model, iterator, device, hook = None):\n",
    "    '''\n",
    "    If Hook is not None.\n",
    "        ex)\n",
    "        hook_model = Hook(model.layer4)\n",
    "        def get_representations(model, test_loader, device, hook = hook_model):\n",
    "    '''\n",
    "    model.eval()\n",
    "\n",
    "    outputs = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in iterator:\n",
    "            \n",
    "            input = data['img'].to(device)\n",
    "            label = data['label']\n",
    "            \n",
    "            output = model(input)\n",
    "            \n",
    "            if hook is not None:\n",
    "                output = hook.features\n",
    "                \n",
    "            outputs.append(output.cpu())\n",
    "            labels.append(label)\n",
    "        \n",
    "    outputs = torch.cat(outputs, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    return outputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(data, n_components = 2):\n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = n_components\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsne(data, n_components = 2):\n",
    "    tsne = manifold.TSNE(n_components = n_components, random_state = 0)\n",
    "    tsne_data = tsne.fit_transform(data)\n",
    "    return tsne_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Representation(PCA, TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_representations(data, labels, n_images = None):\n",
    "    '''\n",
    "    ex)\n",
    "    outputs, labels = get_representation(model, test_loader)\n",
    "    \n",
    "    output_pca = get_pca(outputs)\n",
    "    plot_representations(output_pca, labels)\n",
    "    \n",
    "    output_tsne = get_tsne(outputs)\n",
    "    plot_representations(output_tsne, labels)\n",
    "    '''            \n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        labels = labels[:n_images]\n",
    "                \n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, cmap = 'hsv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans(data, n_cluster, n_images = None):\n",
    "    '''\n",
    "    ex)\n",
    "    outputs, labels = get_representation(model, test_loader)\n",
    "    plot_kmeans(outputs, n_cluster = 5)\n",
    "    '''\n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = n_cluster, random_state = 0)\n",
    "    k_labels = kmeans.fit_predict(data)\n",
    "\n",
    "    unique_labels = np.unique(k_labels)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    plt.figure(figsize = (15, 15))\n",
    "    for i in unique_labels:\n",
    "        plt.scatter(data[k_labels == i, 0], data[k_labels == i, 1], label = i, s = 80, cmap = 'hsv')\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], s = 90, color = 'k', marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy & Difficult "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_easy_difficult(iterator, model, target_layer, device):\n",
    "    '''\n",
    "    ex)\n",
    "    test_easy_difficult(test_loader, model, target_layer = 'layer4', device)\n",
    "    '''\n",
    "\n",
    "    cam = monai.visualize.GradCAM(nn_module=model, target_layers= target_layer)\n",
    "\n",
    "    for data in iterator:\n",
    "        input = data['img'].to(device)\n",
    "        label = data['label']\n",
    "\n",
    "        output = model(input)\n",
    "        _, pred = torch.max(output, dim=1) # max, max_index\n",
    "        \n",
    "        cam_result = cam(input.float().to(device)).permute(0,2,3,1)\n",
    "\n",
    "        for i in range(cam_result.shape[0]): \n",
    "            cam_show = cv2.applyColorMap(np.uint8(cam_result[i].detach().cpu().numpy() * 255), cv2.COLORMAP_JET)/255\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_subplot(121)\n",
    "            ax1.imshow(input[i].detach().cpu().numpy().transpose(1,2,0), 'gray')\n",
    "            ax1.axis('off')\n",
    "\n",
    "            ax2 = fig.add_subplot(122)\n",
    "            ax2.imshow(input[i].detach().cpu().numpy().transpose(1,2,0), 'gray')\n",
    "            ax2.imshow(cam_show, alpha = 0.3)\n",
    "            ax2.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f'GT : {int(label[i])}  Pred : {int(pred[i])}')\n",
    "            fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdaf8225ca8361a4501e29f7f35fc36f6baec4997917c7c75ec5999a985d7c37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('child_x': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
