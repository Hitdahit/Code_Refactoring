{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from math import exp as exp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "from models import resnet_model\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup_seed\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # os 자체의 seed 고정\n",
    "    \n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters & etc.\n",
    "GPU_NUM = 0\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='4'\n",
    "print('gpu? ', torch.cuda.is_available())\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(0,2,3,1)\n",
    "fn_denorm = lambda x, mean, std : (x * std) + mean \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & Loader config\n",
    "\n",
    "EvalDataset = ImageFolder(root = '/eval_set',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                           ]))\n",
    "EvalDataLoader = DataLoader(EvalDataset, batch_size = 32, shuffle=True)\n",
    "\n",
    "# EvalTransForms = A.Compose([    \n",
    "#     A.pytorch.transforms.ToTensorV2()\n",
    "# ])\n",
    "# EvalDataset = Dataset('', EvalTransForms)\n",
    "# EvalDataLoader = DataLoader(EvalDataset, batch_size = 4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample images\n",
    "def DisplaySampleImages(Dataset, labels=True, nrow=4, grid_size=4, padding=2, normalize=True):\n",
    "\n",
    "    grid_size=grid_size\n",
    "    rnd_inds=np.random.randint(0,len(Dataset),grid_size)\n",
    "\n",
    "    images=[Dataset[i][0] for i in rnd_inds]\n",
    "\n",
    "    images=utils.make_grid(images, nrow=nrow, padding=padding, normalize = normalize)\n",
    "\n",
    "\n",
    "    # call helper function\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    npimg = images.numpy()\n",
    "    npimg_tr = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg_tr)\n",
    "    if labels is True:\n",
    "        \n",
    "        labels=[Dataset[i][1] for i in rnd_inds]\n",
    "        plt.title('labels: ' + str(labels))\n",
    "    print(\"image indices:\",rnd_inds)\n",
    "    print(Dataset[0][0].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config \n",
    "num_classes = 2\n",
    "model = resnet_model(num_classes,pretrained = True)\n",
    "dicts = torch.load('/.pth')\n",
    "\n",
    "model.load_state_dict(dicts['net_state_dict'])\n",
    "epoch = dicts['epoch']\n",
    "acc = dicts['acc']\n",
    "\n",
    "model = model.to(device)\n",
    "print('Model Epoch : ',epoch)\n",
    "print('Model Accuracy : ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################  evaluate net and save model  ###############################\n",
    "\n",
    "model.eval()\n",
    "\n",
    "LogitArr=[]\n",
    "LabelArr =[]\n",
    "PredArr = []\n",
    "EvalTotal = 0\n",
    "EvalCorrect = 0\n",
    "for batch_idx, (img, label) in enumerate(EvalDataLoader):\n",
    "    with torch.no_grad():\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        TotalSize = len(EvalDataLoader.dataset)\n",
    "        total_batch = len(EvalDataLoader)\n",
    "        batch_size = len(label)\n",
    "        \n",
    "        Logits = model(imgs=img)\n",
    "        logit = Logits.to('cpu').detach().numpy()\n",
    "        for i in range(len(logit)):\n",
    "            LogitArr.append(logit[i][1])\n",
    "            # LogitArr.append(logit[i][logit[i].argmax()])\n",
    "            PredArr.append(np.argmax(logit[i],axis=0))\n",
    "            \n",
    "        labels = label.to('cpu').detach().numpy()\n",
    "        for i in range(len(labels)):\n",
    "            LabelArr.append(labels[i]) \n",
    "        \n",
    "        # calculate accuracy\n",
    "        \n",
    "        EvalTotal += batch_size\n",
    "        EvalCorrect += (torch.max(Logits, 1)[1]==label.data).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate roauc\n",
    " \n",
    "def CalculateAuc(y_true, y_score):\n",
    "    fprs , tprs , thresholds = roc_curve(np.array(y_true), np.array(y_score))\n",
    "    roauc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    plt.plot(fprs, tprs, color='red', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--', label='Random')\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.yticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('False Positive Rate (1 - Sensitivity)')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('AUC: {:.4f}'.format(roauc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetEvalMetrics(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    F1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print('Accuracy: {:.4f}'.format(accuracy))\n",
    "    print('Precision: {:.4f}'.format(precision))\n",
    "    print('Recall: {:.4f}'.format(recall))\n",
    "    print('F1: {:.4f}'.format(F1))\n",
    "    print('예측값 10개만 표시: ', y_pred[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(y_true, y_pred, title='Confusion matrix', cmap='Blues',normalize= None):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,cmap=cmap,normalize = normalize )\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    print('Confusion matrix:\\n', confusion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install grad-cam\n",
    "def SimpleCam(model, DataLoader, target_layers):\n",
    "    for i, (img, label) in enumerate(DataLoader):   \n",
    "        img, label = img.to(device), label.to(device)\n",
    "        input_tensor = img\n",
    "        # Create an input tensor image for your model..\n",
    "        # Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "        # Construct the CAM object once, and then re-use it on many images:\n",
    "        cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
    "\n",
    "        # You can also use it within a with statement, to make sure it is freed,\n",
    "        # In case you need to re-create it inside an outer loop:\n",
    "        # with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam:\n",
    "        #   ...\n",
    "\n",
    "        # We have to specify the target we want to generate\n",
    "        # the Class Activation Maps for.\n",
    "        # If targets is None, the highest scoring category\n",
    "        # will be used for every image in the batch.\n",
    "        # Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
    "        # That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
    "        \n",
    "        targets = None\n",
    "        # targets = [ClassifierOutputTarget(1)]\n",
    "        # targets = [ClassifierOutputTarget(0)]\n",
    "        \n",
    "        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "        # In this example grayscale_cam has only one image in the batch:\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        np_arr = fn_tonumpy(img)\n",
    "        np_arr = np_arr[0,:]\n",
    "        visualization = show_cam_on_image(np_arr, grayscale_cam, use_rgb=True)\n",
    "        fig = plt.figure()\n",
    "        rows = 1\n",
    "        cols = 2\n",
    "        ax1 = fig.add_subplot(rows, cols, 1)\n",
    "        ax1.axis(\"off\")\n",
    "        plt.imshow(np_arr)\n",
    "        ax2 = fig.add_subplot(rows, cols, 2)\n",
    "        plt.imshow(visualization)\n",
    "        ax2.axis(\"off\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetEvalMetrics(LabelArr,PredArr)\n",
    "\n",
    "CalculateAuc(LabelArr, LogitArr)\n",
    "\n",
    "DisplaySampleImages(EvalDataset)\n",
    "\n",
    "# pip install -U scikit-learn\n",
    "ConfusionMatrix(LabelArr,PredArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleCam(model, EvalDataLoader,[model.model.layer4])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d71735a36355f205cc18ca1a005e60445401aeeaa3222dc20d978828187f5e2c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
