{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from math import exp as exp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from models import resnet_model\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters & etc.\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & Loader config\n",
    "\n",
    "EvalDataset = ImageFolder(root = '/eval_set',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                           ]))\n",
    "EvalDataLoader = DataLoader(EvalDataset, batch_size = 32, shuffle=True)\n",
    "\n",
    "# EvalTransForms = A.Compose([    \n",
    "#     A.pytorch.transforms.ToTensorV2()\n",
    "# ])\n",
    "# EvalDataset = Dataset('', EvalTransForms)\n",
    "# EvalDataLoader = DataLoader(EvalDataset, batch_size = 4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample images\n",
    "def Display_Sample_Images(Dataset, labels=True, nrow=4, grid_size=4, padding=2, normalize=True):\n",
    "\n",
    "    grid_size=grid_size\n",
    "    \n",
    "    image_indices = np.random.randint(0,len(Dataset),grid_size)\n",
    "    \n",
    "    images=[Dataset[i][0] for i in image_indices]\n",
    "    \n",
    "    images=utils.make_grid(images, nrow=nrow, padding=padding, normalize = normalize)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    npimg = images.numpy()\n",
    "    npimg_tr = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg_tr)\n",
    "    \n",
    "    if labels is True:\n",
    "        labels=[Dataset[i][1] for i in image_indices]\n",
    "        plt.title('labels: ' + str(labels))\n",
    "        \n",
    "    print(\"image indices:\",image_indices)\n",
    "    print(Dataset[0][0].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config \n",
    "num_classes = 2\n",
    "model = resnet_model(num_classes,pretrained = True)\n",
    "dicts = torch.load('/.pth')\n",
    "\n",
    "model.load_state_dict(dicts['net_state_dict'])\n",
    "epoch = dicts['epoch']\n",
    "acc = dicts['acc']\n",
    "\n",
    "model = model.to(device)\n",
    "print('Model Epoch : ',epoch)\n",
    "print('Model Accuracy : ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################  evaluate net and save model  ###############################\n",
    "\n",
    "model.eval()\n",
    "\n",
    "LogitArr=[]\n",
    "LabelArr =[]\n",
    "PredArr = []\n",
    "EvalTotal = 0\n",
    "EvalCorrect = 0\n",
    "for batch_idx, (img, label) in enumerate(EvalDataLoader):\n",
    "    with torch.no_grad():\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        TotalSize = len(EvalDataLoader.dataset)\n",
    "        total_batch = len(EvalDataLoader)\n",
    "        batch_size = len(label)\n",
    "        \n",
    "        Logits = model(imgs=img)\n",
    "        logit = Logits.to('cpu').detach().numpy()\n",
    "        for i in range(len(logit)):\n",
    "            LogitArr.append(logit[i][1])\n",
    "            # LogitArr.append(logit[i][logit[i].argmax()])\n",
    "            PredArr.append(np.argmax(logit[i],axis=0))\n",
    "            \n",
    "        labels = label.to('cpu').detach().numpy()\n",
    "        for i in range(len(labels)):\n",
    "            LabelArr.append(labels[i]) \n",
    "        \n",
    "        # calculate accuracy\n",
    "        \n",
    "        EvalTotal += batch_size\n",
    "        EvalCorrect += (torch.max(Logits, 1)[1]==label.data).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC계산\n",
    " \n",
    "def Calculate_AUC(y_true, y_score, thresholds = False ):\n",
    "    fprs , tprs , thresholds = roc_curve(np.array(y_true), np.array(y_score))\n",
    "    roauc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    plt.plot(fprs, tprs, color='red', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--', label='Random')\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.yticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('False Positive Rate (1 - Sensitivity)')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('AUC: {:.4f}'.format(roauc))\n",
    "    if thresholds is True:\n",
    "        print('Thresholds: ', thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics 계산\n",
    "\n",
    "def Get_Eval_Metrics(y_true, y_pred, average = 'binary', mode = 'BC', pos_label = 1):\n",
    "    \"\"\"\n",
    "    -average종류-\n",
    "    'binary': 이진분류 지정한 클래스에 대한 결과만 보고함( pos_label default=1)\n",
    "    'micro': 전체 평균으로 모든 열에서 맞은 것 즉, 대각선 성분의 총 합을 총 갯수로 나눈 것 (개수 그자체로 평균),  데이터 불균형일때 조금더 효과적 \n",
    "    'macro': average를 None으로 두었을 때 구한 각 열의 Precision들을 산술 평균한 값이 macro가 된다 (평균의 평균을 내는 방법). (normal+abnormal)/2*precision or recall or f1 score\n",
    "    'weighted': 각 레이블에 대한 메트릭을 계산하고 지원에 따라 가중치가 부여된 평균(각 레이블에 대한 실제 인스턴스 수)을 찾는다. normal/(normal+abnormal)*precision or recall or f1 score\n",
    "    'samples': 각 인스턴스에 대한 지표를 계산하고 평균을 찾음, accuracy_score와 다른 다중 레이블 분류에만 의미가 있다\n",
    "    \n",
    "    \"\"\"\n",
    "    if mode is 'ML':\n",
    "        average = 'samples'\n",
    "    if mode is 'MC':\n",
    "        average = None\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=average, pos_label = pos_label)\n",
    "    recall = recall_score(y_true, y_pred, average=average, pos_label = pos_label)\n",
    "    F1 = f1_score(y_true, y_pred, average=average, pos_label = pos_label)\n",
    "    ClassificationReport = classification_report(y_true, y_pred)\n",
    "    if average is None:\n",
    "            print('Accuracy (Exact Match Ratio): ', accuracy)\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "            print('F1: ', F1)\n",
    "            print('Classification Report: \\n', ClassificationReport)\n",
    "            print('예측값 10개만 표시: ', y_pred[:10])\n",
    "    else:\n",
    "        print('Accuracy (Exact Match Ratio): {:.4f}'.format(accuracy))\n",
    "        print('Precision: {:.4f}'.format(precision))\n",
    "        print('Recall: {:.4f}'.format(recall))\n",
    "        print('F1: {:.4f}'.format(F1))\n",
    "        print('Classification Report: \\n', ClassificationReport)\n",
    "        print('예측값 10개만 표시: ', y_pred[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_Matrix(y_true, y_pred, title='Confusion matrix', cmap='Blues',normalize= None):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,cmap=cmap,normalize = normalize )\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    print('Confusion matrix:\\n', confusion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAM 설치 \n",
    "# !pip install grad-cam\n",
    "\n",
    "fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(0,2,3,1) # numpy 로 변환\n",
    "\n",
    "def SimpleCam(model, DataLoader, target_layers, use_cuda=True):\n",
    "    for i, (img, label) in enumerate(DataLoader):   \n",
    "        img, label = img.to(device), label.to(device)\n",
    "        input_tensor = img\n",
    "\n",
    "        # input_tensor는 배치랑 이미지 상관없이 넣을수 있다.\n",
    "\n",
    "        cam = GradCAM(model = model, target_layers = target_layers, use_cuda = use_cuda)\n",
    "\n",
    "        # targets = 어떤클래스를 보고있는지 확인\n",
    "        targets = None\n",
    "        # targets = [ClassifierOutputTarget(1)]\n",
    "        # targets = [ClassifierOutputTarget(0)]\n",
    "        \n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets) # aug_smooth=True 와 eigen_smooth=True 로 CAM의 결과물 smoothing 가능\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        np_arr = fn_tonumpy(img)\n",
    "        np_arr = np_arr[0,:]\n",
    "        visualization = show_cam_on_image(np_arr, grayscale_cam, use_rgb=True)\n",
    "        fig = plt.figure()\n",
    "        rows = 1\n",
    "        cols = 2\n",
    "        ax1 = fig.add_subplot(rows, cols, 1)\n",
    "        ax1.axis(\"off\")\n",
    "        plt.imshow(np_arr)\n",
    "        ax2 = fig.add_subplot(rows, cols, 2)\n",
    "        plt.imshow(visualization)\n",
    "        ax2.axis(\"off\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Get_Eval_Metrics(LabelArr,PredArr)\n",
    "\n",
    "Calculate_AUC(LabelArr, LogitArr)\n",
    "\n",
    "Display_Sample_Images(EvalDataset)\n",
    "\n",
    "# pip install -U scikit-learn\n",
    "Confusion_Matrix(LabelArr,PredArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleCam(model, EvalDataLoader,[model.model.layer4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d71735a36355f205cc18ca1a005e60445401aeeaa3222dc20d978828187f5e2c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
