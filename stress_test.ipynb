{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import cv2\n",
    "import monai # gradcam 사용하기 위함\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import manifold # TSNE 사용\n",
    "from sklearn.decomposition import PCA # PCA 사용\n",
    "from sklearn.cluster import KMeans # KMeans 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Image input 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input(iterator, nrow): # iterator = dataloader, nrow = plot하고 싶은 열의 개수\n",
    "    for data in iterator:\n",
    "        input = data['img']\n",
    "        label = data['label']\n",
    "        \n",
    "        # nrow로 한 행의 열 갯수 정함(행 갯수 : batch_size / nrow), permute(1,2,0) : [C,H,W] -> [H,W,C]\n",
    "        plt.imshow(torchvision.utils.make_grid(input, nrow=nrow,normalize=True).permute(1,2,0)) \n",
    "        print(''.join(f'{label[i]} 'for i in range(input.shape[0]))) # input.shape[0] : batch_size \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook():\n",
    "    def __init__(self, module, backward = False): \n",
    "        if backward == False:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn) # 순전파 진행할때의 feature 뽑을때 사용\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn) # 역전파 진행할때의 feature 뽑을때 사용\n",
    "    def hook_fn(self, module, input, output): \n",
    "        self.input = input # hook.input : hook이 걸린 layer input 값\n",
    "        self.features = output # hook.feauture : hook이 걸린 layer output 값\n",
    "    def close(self):\n",
    "        self.hook.remove() # hook 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representations(model, iterator, device, hook = None): \n",
    "    '''\n",
    "    If Hook is not None.\n",
    "        ex)\n",
    "        hook_model = Hook(model.layer4) \n",
    "        def get_representations(model, test_loader, device, hook = hook_model):\n",
    "    '''\n",
    "    model.eval()\n",
    "\n",
    "    outputs = [] \n",
    "    labels = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in iterator:\n",
    "            input = data['img'].to(device) \n",
    "            label = data['label']\n",
    "            \n",
    "            output = model(input) # 모델 마지막 층 output\n",
    "            \n",
    "            if hook is not None: # hook이 걸려있다면\n",
    "                output = hook.features # output : hook이 걸려있는 layer의 output\n",
    "                \n",
    "            outputs.append(output.cpu()) # pca, tsne, kmeans 사용하기 위해 gpu -> cpu\n",
    "            labels.append(label) \n",
    "    \n",
    "    # batch 기준으로 다시 concat \n",
    "    outputs = torch.cat(outputs, dim = 0)  \n",
    "    labels = torch.cat(labels, dim = 0) \n",
    "    return outputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(data, n_components = 2): \n",
    "    pca = PCA(n_components= n_components) # n_components 값으로 차원 축소 설정\n",
    "    pca_data = pca.fit_transform(data) # 위의 조건 적용\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsne(data, n_components = 2):\n",
    "    tsne = manifold.TSNE(n_components = n_components, random_state = 0) # n_components 값으로 차원 축소 설정\n",
    "    tsne_data = tsne.fit_transform(data) # 위의 조건 적용\n",
    "    return tsne_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Representation(PCA, TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_representations(data, labels, n_images = None):\n",
    "    '''\n",
    "    ex)\n",
    "    outputs, labels = get_representation(model, test_loader)\n",
    "    \n",
    "    output_pca = get_pca(outputs)\n",
    "    plot_representations(output_pca, labels)\n",
    "    \n",
    "    output_tsne = get_tsne(outputs)\n",
    "    plot_representations(output_tsne, labels)\n",
    "    '''            \n",
    "    if n_images is not None: # feature extraction에서 원하는 갯수의 feature만 사용할때\n",
    "        data = data[:n_images]\n",
    "        labels = labels[:n_images]\n",
    "                \n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, cmap = 'hsv') # 데이터 라벨별 다른 color를 적용\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans(data, n_cluster, n_images = None):\n",
    "    '''\n",
    "    ex)\n",
    "    outputs, labels = get_representation(model, test_loader)\n",
    "    plot_kmeans(outputs, n_cluster = 5)\n",
    "    '''\n",
    "    if n_images is not None: # feature extraction에서 원하는 갯수의 feature만 사용할때\n",
    "        data = data[:n_images]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = n_cluster, random_state = 0) # 몇개의 cluster를 만들지 설정\n",
    "    k_labels = kmeans.fit_predict(data) # 위의 조건 적용\n",
    "\n",
    "    unique_labels = np.unique(k_labels) # label의 unique 값을 담은 list\n",
    "    centroids = kmeans.cluster_centers_ # 만들어진 cluster의 center값을 담은 list\n",
    "    \n",
    "    plt.figure(figsize = (15, 15))\n",
    "    for i in unique_labels: \n",
    "        # label별로 색을 다르게 해서 하나의 figure에 겹쳐서 뿌림\n",
    "        plt.scatter(data[k_labels == i, 0], data[k_labels == i, 1], label = i, s = 80, cmap = 'hsv')\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], s = 90, color = 'k', marker='x') # 각 cluster의 center 표시\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy & Difficult "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_easy_difficult(iterator, model, target_layer, device):\n",
    "    '''\n",
    "    ex)\n",
    "    test_easy_difficult(test_loader, model, target_layer = 'layer4', device)\n",
    "    '''\n",
    "\n",
    "    cam = monai.visualize.GradCAM(nn_module=model, target_layers= target_layer)\n",
    "\n",
    "    for data in iterator:\n",
    "        input = data['img'].to(device)\n",
    "        label = data['label']\n",
    "\n",
    "        output = model(input)\n",
    "        _, pred = torch.max(output, dim=1) # _ : max, pred : max_index binary로 생각하고 만들었음 그때 그때 달라져야함\n",
    "        # grad cam 결과, [b,c,h,w -> b,h,w,c] : opencv로 colormap 적용하기 위함\n",
    "        cam_result = cam(input.float().to(device)).permute(0,2,3,1) \n",
    "\n",
    "        for i in range(cam_result.shape[0]): # cam_result.shape[0] : batchsize\n",
    "            # opencv 쓰기 위해 gpu -> cpu, 0~1로 normalize된 이미지를 0~255범위로 변경 후 colormap 적용\n",
    "            # -> (0 ~ 1)범위인 image와 겹쳐서 표현하기 위해 다시 255로 나눔\n",
    "            cam_show = cv2.applyColorMap(np.uint8(cam_result[i].detach().cpu().numpy() * 255), cv2.COLORMAP_JET)/255\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_subplot(121)\n",
    "            ax1.imshow(input[i].detach().cpu().numpy().transpose(1,2,0), 'gray')\n",
    "            ax1.axis('off')\n",
    "\n",
    "            ax2 = fig.add_subplot(122)\n",
    "            ax2.imshow(input[i].detach().cpu().numpy().transpose(1,2,0), 'gray')\n",
    "            ax2.imshow(cam_show, alpha = 0.3) # glay scale 이미지에 투명도 0.3인 cam 사진 겹치게 함 \n",
    "            ax2.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f'GT : {int(label[i])}  Pred : {int(pred[i])}') # title에 \"GT : label Pred : label\" 표시\n",
    "            fig.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdaf8225ca8361a4501e29f7f35fc36f6baec4997917c7c75ec5999a985d7c37"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
